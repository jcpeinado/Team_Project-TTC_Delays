{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning for the Team Project TTC Delay\n",
    "\n",
    "Objective:\n",
    "\n",
    "This code prepares the data for analysis by merging datasets for period Jan, 01, 2024 to Jan 31, 2025, cleaning up unnecessary columns, and standardizing date formats. It sets the foundation for further exploration and visualization of TTC subway delays.\n",
    "The  the result for years 2024 and 2025 datasets are concatenated into a single DataFrame named 'df_delay.csv' and saved at directory  '../data/processed_data/df_delay.csv'.\n",
    "\n",
    "Files Used:\n",
    "1. ttc-subway-delay-data-2024.csv:\n",
    " - this file contains TTC subway delay data for the year 2024.\n",
    " - it is loaded into a DataFrame named df_2024 using pd.read_csv().\n",
    "\n",
    "2. TTC Subway Delay Data since 2025.csv:\n",
    " - this file contains TTC subway delay data for month of January of 2025.\n",
    "\n",
    "3. code_category_description.csv \n",
    "- file to categorize various delay codes related to transportation operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Description\n",
    "* Date Range: Jan, 01 2024 to Jan 31, 2025\n",
    "* Company:The Toronto subway, operated by the TTC (Toronto Transit Commission), consists of three lines: Line 1 (Yonge-University), Line 2 (Bloor-Danforth), and Line 4 (Sheppard). \n",
    "* Data Points: 28,571 entries \n",
    "* Adjustments: 17,653 entries in dataset 'df_delay.csv'\n",
    "* Additional source: 'code_category_description.csv' (130 entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Importing Necessary Libraries:\n",
    "\n",
    "There are loster essential libraries required for data manipulation, visualization and modeling done in this project:\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning and Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Deep Learning \n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Day</th>\n",
       "      <th>Station</th>\n",
       "      <th>Code</th>\n",
       "      <th>Min Delay</th>\n",
       "      <th>Min Gap</th>\n",
       "      <th>Bound</th>\n",
       "      <th>Line</th>\n",
       "      <th>Vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>Monday</td>\n",
       "      <td>SHEPPARD STATION</td>\n",
       "      <td>MUI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>YU</td>\n",
       "      <td>5491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>Monday</td>\n",
       "      <td>DUNDAS STATION</td>\n",
       "      <td>MUIS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>YU</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>02:08</td>\n",
       "      <td>Monday</td>\n",
       "      <td>DUNDAS STATION</td>\n",
       "      <td>MUPAA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>N</td>\n",
       "      <td>YU</td>\n",
       "      <td>6051.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>02:13</td>\n",
       "      <td>Monday</td>\n",
       "      <td>KENNEDY BD STATION</td>\n",
       "      <td>PUTDN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>E</td>\n",
       "      <td>BD</td>\n",
       "      <td>5284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>02:22</td>\n",
       "      <td>Monday</td>\n",
       "      <td>BLOOR STATION</td>\n",
       "      <td>MUPAA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>N</td>\n",
       "      <td>YU</td>\n",
       "      <td>5986.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Time     Day             Station   Code  Min Delay  Min Gap  \\\n",
       "0 2024-01-01  02:00  Monday    SHEPPARD STATION    MUI        0.0      0.0   \n",
       "1 2024-01-01  02:00  Monday      DUNDAS STATION   MUIS        0.0      0.0   \n",
       "2 2024-01-01  02:08  Monday      DUNDAS STATION  MUPAA        4.0     10.0   \n",
       "3 2024-01-01  02:13  Monday  KENNEDY BD STATION  PUTDN       10.0     16.0   \n",
       "4 2024-01-01  02:22  Monday       BLOOR STATION  MUPAA        4.0     10.0   \n",
       "\n",
       "  Bound Line  Vehicle  \n",
       "0     N   YU   5491.0  \n",
       "1     N   YU      0.0  \n",
       "2     N   YU   6051.0  \n",
       "3     E   BD   5284.0  \n",
       "4     N   YU   5986.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cload the data for years 2024 and 2025\n",
    "df_2024 = pd.read_csv(\"../data/raw_data/ttc-subway-delay-data-2024.csv\")\n",
    "\n",
    "df_2025 = pd.read_csv(\"../data/raw_data/TTC Subway Delay Data since 2025.csv\")\n",
    "\n",
    "#drop column '_id'\n",
    "df_2025 = df_2025.drop(columns='_id')\n",
    "\n",
    "# Converting the 'Date' column in both dataframes to datetime objects.\n",
    "df_2024['Date'] = pd.to_datetime(df_2024['Date'])\n",
    "df_2025['Date'] = pd.to_datetime(df_2025['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# concatename the datast for the 2024, 2025\n",
    "df = pd.concat([df_2024, df_2025], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28571 entries, 0 to 28570\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       28571 non-null  datetime64[ns]\n",
      " 1   Time       28571 non-null  object        \n",
      " 2   Day        28571 non-null  object        \n",
      " 3   Station    28571 non-null  object        \n",
      " 4   Code       28571 non-null  object        \n",
      " 5   Min Delay  27275 non-null  float64       \n",
      " 6   Min Gap    27230 non-null  float64       \n",
      " 7   Bound      18329 non-null  object        \n",
      " 8   Line       28522 non-null  object        \n",
      " 9   Vehicle    27754 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), object(6)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the data types and non-null counts\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          397\n",
       "Time         1426\n",
       "Day             7\n",
       "Station       473\n",
       "Code          125\n",
       "Min Delay     109\n",
       "Min Gap       106\n",
       "Bound           5\n",
       "Line           22\n",
       "Vehicle       786\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique values\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['YU', 'BD', 'YUS', 'YU/BD', 'SHP', nan, 'BLOOR DANFORTH',\n",
       "       'YU / BD', 'YU/ BD', 'YUS/BD', 'SHEP', 'LINE 1',\n",
       "       'TRACK LEVEL ACTIVITY', 'YU & BD', '109 RANEE',\n",
       "       'ONGE-UNIVERSITY AND BL', 'YU/BD/SHP', 'BD/ YUS', 'BD/ YU',\n",
       "       'BD/YU', 'BD / YU', '20 CLIFFSIDE'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing SRT Line as it is not in use\n",
    "df = df[df['Line'] != 'SRT']\n",
    "df['Line'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date             0\n",
      "Time             0\n",
      "Day              0\n",
      "Station          0\n",
      "Code             0\n",
      "Min Delay     1296\n",
      "Min Gap       1341\n",
      "Bound        10240\n",
      "Line            49\n",
      "Vehicle        817\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    " #count isnull values per columns\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Vehicle\" column, which provides the registered number of the train conducting the TTC trip, is deemed irrelevant for the purposes of our analysis. Consequently, this data may be considered for removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.drop('Vehicle',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Missing Values\n",
    "\n",
    "Given the dataset containing 28,572 entries, we have opted to address missing values by removing rows with null values. This decision is informed by the observation that the column \"Bound\" possesses the largest number of missing entries, totaling 10,240. While this represents a significant portion of the missing data, it constitutes only a fraction of the overall dataset. Consequently, the removal of these entries is expected to have minimal impact on the integrity and representativeness of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date             0\n",
      "Time             0\n",
      "Day              0\n",
      "Station          0\n",
      "Code             0\n",
      "Min Delay     1296\n",
      "Min Gap       1341\n",
      "Bound        10240\n",
      "Line            49\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    " #count isnull values per columns\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop isnull values in Min Delay and columns\n",
    "df_cleaned = df.dropna() #Nan  0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17695 entries, 0 to 28570\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       17695 non-null  datetime64[ns]\n",
      " 1   Time       17695 non-null  object        \n",
      " 2   Day        17695 non-null  object        \n",
      " 3   Station    17695 non-null  object        \n",
      " 4   Code       17695 non-null  object        \n",
      " 5   Min Delay  17695 non-null  float64       \n",
      " 6   Min Gap    17695 non-null  float64       \n",
      " 7   Bound      17695 non-null  object        \n",
      " 8   Line       17695 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()   #28571    17695 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date         0\n",
      "Time         0\n",
      "Day          0\n",
      "Station      0\n",
      "Code         0\n",
      "Min Delay    0\n",
      "Min Gap      0\n",
      "Bound        0\n",
      "Line         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    " #count isnull values per column\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional features\n",
    "\n",
    "To enhance the dataset, additional features were derived from the existing \"Date\" column. \n",
    "Specifically:\n",
    "- a new column labeled \"Month\" was created, extracting the numerical representation of the month (ranging from 1 to 12) from the \"Date\" values.\n",
    "- another column titled \"Month Name\" was added, containing the full textual names of the months (e.g., January, February) corresponding to the \"Date\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Time     Day             Station   Code  Min Delay  Min Gap  \\\n",
      "0 2024-01-01  02:00  Monday    SHEPPARD STATION    MUI        0.0      0.0   \n",
      "1 2024-01-01  02:00  Monday      DUNDAS STATION   MUIS        0.0      0.0   \n",
      "2 2024-01-01  02:08  Monday      DUNDAS STATION  MUPAA        4.0     10.0   \n",
      "3 2024-01-01  02:13  Monday  KENNEDY BD STATION  PUTDN       10.0     16.0   \n",
      "4 2024-01-01  02:22  Monday       BLOOR STATION  MUPAA        4.0     10.0   \n",
      "\n",
      "  Bound Line  Month Month Name  \n",
      "0     N   YU      1    January  \n",
      "1     N   YU      1    January  \n",
      "2     N   YU      1    January  \n",
      "3     E   BD      1    January  \n",
      "4     N   YU      1    January  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2712\\1454598829.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Month'] = df_cleaned['Date'].dt.month\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2712\\1454598829.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Month Name'] = df_cleaned['Date'].dt.month_name()\n"
     ]
    }
   ],
   "source": [
    "# Creating new features from 'Date' column\n",
    "df_cleaned['Month'] = df_cleaned['Date'].dt.month\n",
    "\n",
    "# Adding a new column with month names\n",
    "df_cleaned['Month Name'] = df_cleaned['Date'].dt.month_name()\n",
    "\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Code\" column, which identifies the specific reasons for TTC delays, has been categorized to streamline the analytical process. The categorization was informed by information sourced from online references, which was subsequently incorporated into the dataset titled 'code_category_description.csv'. This approach aims to enhance the clarity and efficiency of the analysis by grouping similar delay codes under broader, defined categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Delay Code                                 Category  \\\n",
      "0         EUAC  Mechanical/Electrical/Vehicle Equipment   \n",
      "1         EUAL  Mechanical/Electrical/Vehicle Equipment   \n",
      "2        EUATC  Mechanical/Electrical/Vehicle Equipment   \n",
      "3         EUBK  Mechanical/Electrical/Vehicle Equipment   \n",
      "4         EUBO  Mechanical/Electrical/Vehicle Equipment   \n",
      "..         ...                                      ...   \n",
      "124        TUS                  Transportation/Operator   \n",
      "125       TUSC                  Transportation/Operator   \n",
      "126      TUSET                  Transportation/Operator   \n",
      "127       TUST                         Weather/External   \n",
      "128      TUSUP                  Transportation/Operator   \n",
      "\n",
      "                                           Description  \n",
      "0           Train HVAC malfunction or underperformance  \n",
      "1      Issues with onboard or wayside AC power systems  \n",
      "2    ATC equipment malfunction related to Rail Cars...  \n",
      "3          Faulty brake components or pneumatic issues  \n",
      "4        Structural or body-related train car problems  \n",
      "..                                                 ...  \n",
      "124                   Crew unable to maintain schedule  \n",
      "125     Operator overspeeding or ignoring speed limits  \n",
      "126                Train controls improperly shut down  \n",
      "127  Storm trains or slow orders due to severe weather  \n",
      "128       Supervisory error causing service disruption  \n",
      "\n",
      "[129 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# add dataset for Code categories\n",
    "df_code = pd.read_csv(\"../data/raw_data/code_category_description.csv\")\n",
    "print(df_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Values per Column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Delay Code     129\n",
       "Category        11\n",
       "Description    129\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique values\n",
    "print(\"\\nUnique Values per Column:\")\n",
    "df_code.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129 entries, 0 to 128\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Delay Code   129 non-null    object\n",
      " 1   Category     129 non-null    object\n",
      " 2   Description  129 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_code.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 'Category' column from df_code to df_cleanese based on 'Delay code'\n",
    "df_delay = pd.merge(df_cleaned, df_code, left_on='Code', right_on = 'Delay Code',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17653 entries, 0 to 17652\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Date         17653 non-null  datetime64[ns]\n",
      " 1   Time         17653 non-null  object        \n",
      " 2   Day          17653 non-null  object        \n",
      " 3   Station      17653 non-null  object        \n",
      " 4   Code         17653 non-null  object        \n",
      " 5   Min Delay    17653 non-null  float64       \n",
      " 6   Min Gap      17653 non-null  float64       \n",
      " 7   Bound        17653 non-null  object        \n",
      " 8   Line         17653 non-null  object        \n",
      " 9   Month        17653 non-null  int32         \n",
      " 10  Month Name   17653 non-null  object        \n",
      " 11  Delay Code   17653 non-null  object        \n",
      " 12  Category     17653 non-null  object        \n",
      " 13  Description  17653 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int32(1), object(10)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_delay.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date           0\n",
      "Time           0\n",
      "Day            0\n",
      "Station        0\n",
      "Code           0\n",
      "Min Delay      0\n",
      "Min Gap        0\n",
      "Bound          0\n",
      "Line           0\n",
      "Month          0\n",
      "Month Name     0\n",
      "Delay Code     0\n",
      "Category       0\n",
      "Description    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    " #count isnull values per column\n",
    "print(df_delay.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns \"Delay Code\" and \"Description\" contain redundant information and may be considered for removal from the dataset to enhance clarity and reduce unnecessary duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop redundant columns\n",
    "df_delay =  df_delay.drop(['Delay Code','Description'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by date, time\n",
    "df_delay = df_delay.sort_values(by=['Date', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   Time     Day                Station   Code  Min Delay  \\\n",
      "38 2024-01-01  00:44  Monday     VAUGHAN MC STATION  MUPAA        0.0   \n",
      "39 2024-01-01  00:48  Monday          BLOOR STATION    SUO        0.0   \n",
      "40 2024-01-01  01:10  Monday     VAUGHAN MC STATION    MUO        8.0   \n",
      "41 2024-01-01  01:11  Monday         DUNDAS STATION    SUO        0.0   \n",
      "42 2024-01-01  01:38  Monday  ST GEORGE YUS STATION   SUUT        0.0   \n",
      "\n",
      "    Min Gap Bound Line  Month Month Name                           Category  \n",
      "38      0.0     S   YU      1    January  Door/Passenger/Platform Incidents  \n",
      "39      0.0     S   YU      1    January                  Security/Policing  \n",
      "40     14.0     S   YU      1    January                      Miscellaneous  \n",
      "41      0.0     S   YU      1    January                  Security/Policing  \n",
      "42      0.0     N   YU      1    January                  Security/Policing  \n"
     ]
    }
   ],
   "source": [
    "# Printing new dataframe after creation of new features\n",
    "print(df_delay.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been saved to: ../data/processed_data/df_delay.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path where the dataset should be saved\n",
    "file_path = '../data/processed_data/df_delay.csv'  \n",
    "\n",
    "# Save the dataset as a CSV file\n",
    "df_delay.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Dataset has been saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
